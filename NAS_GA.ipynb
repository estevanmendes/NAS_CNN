{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 17:35:09.609606: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-25 17:35:09.653115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-25 17:35:10.508653: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "from deap import base, creator,tools,algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_datasets():\n",
    "    class Dataframe2ImageDataset:\n",
    "        @staticmethod\n",
    "        def load_image(filepath):\n",
    "            raw = tf.io.read_file(filepath)        \n",
    "            tensor = tf.io.decode_image(raw)\n",
    "            tensor = tf.cast(tensor, tf.float32) / 255.0\n",
    "            return tensor\n",
    "\n",
    "        def __init__(self,df,path_column,label_column) -> None:\n",
    "            self.paths=df[path_column].values\n",
    "            self.labels=np.eye(2)[df[label_column].values]\n",
    "\n",
    "        def create_dataset(self):\n",
    "            dataset = tf.data.Dataset.from_tensor_slices((self.paths,self.labels))\n",
    "            dataset = dataset.map(lambda filepath, label: (self.load_image(filepath), label))\n",
    "            # self.dataset=dataset\n",
    "            return dataset\n",
    "        \n",
    "    trainning_df=pd.read_csv('trainning_dataset.csv')\n",
    "    validation_df=pd.read_csv('validation_dataset.csv')\n",
    "    testing_df=pd.read_csv('testing_dataset.csv')\n",
    "\n",
    "    training_dataset=Dataframe2ImageDataset(trainning_df,'path','binary_label_code').create_dataset()\n",
    "    validation_dataset=Dataframe2ImageDataset(validation_df,'path','binary_label_code').create_dataset()\n",
    "    testing_dataset=Dataframe2ImageDataset(testing_df,'path','binary_label_code').create_dataset()\n",
    "    return training_dataset,validation_dataset,testing_dataset\n",
    "\n",
    "def individuals(max_depth=15):\n",
    "    pool_of_features={1:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':64,'kernel_size':5,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    2:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':32,'kernel_size':5,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    3:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':16,'kernel_size':5,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    4:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':8,'kernel_size':5,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    5:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':64,'kernel_size':3,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    6:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':32,'kernel_size':3,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    7:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':16,'kernel_size':3,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    8:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':8,'kernel_size':3,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    9:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':8,'kernel_size':3,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    10:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':64,'kernel_size':1,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    11:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':32,'kernel_size':1,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    12:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':16,'kernel_size':1,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    13:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':8,'kernel_size':1,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    14:{'layer':tf.keras.layers.Conv2D,\n",
    "                        'params':{'filters':8,'kernel_size':1,'strides':1,'padding':'valid','activation':'relu'}},\n",
    "                    15:{'layer':tf.keras.layers.BatchNormalization,\n",
    "                        'params':{}},\n",
    "                    16:{'layer':tf.keras.layers.MaxPool2D,\n",
    "                        'params':{'pool_size':(2,2)}},\n",
    "                    17:{'layer':tf.keras.layers.MaxPool2D,\n",
    "                        'params':{'pool_size':(4,4)}},\n",
    "                    18:{'layer':tf.keras.layers.MaxPool2D,\n",
    "                        'params':{'pool_size':(6,6)}},\n",
    "                    19:{'layer':tf.keras.layers.MaxPool2D,\n",
    "                        'params':{'pool_size':(8,8)}},\n",
    "                    20:{'layer':tf.keras.layers.MaxPool2D,\n",
    "                        'params':{'pool_size':(10,10)}},\n",
    "                    21:{'layer':tf.keras.layers.AveragePooling2D,\n",
    "                        'params':{'pool_size':(2,2)}},\n",
    "                    22:{'layer':tf.keras.layers.AveragePooling2D,\n",
    "                        'params':{'pool_size':(4,4)}},\n",
    "                    23:{'layer':tf.keras.layers.AveragePooling2D,\n",
    "                        'params':{'pool_size':(6,6)}},\n",
    "                    24:{'layer':tf.keras.layers.AveragePooling2D,\n",
    "                        'params':{'pool_size':(10,10)}},\n",
    "                    25:{'layer':tf.keras.layers.GlobalMaxPool2D,\n",
    "                        'params':{}}, \n",
    "                    26:{'layer':tf.keras.layers.Dense,\n",
    "                        'params':{'units':100,'activation':'relu'}},\n",
    "                    27:{'layer':tf.keras.layers.Dense,\n",
    "                        'params':{'units':80,'activation':'relu'}},\n",
    "                    28:{'layer':tf.keras.layers.Dense,\n",
    "                        'params':{'units':60,'activation':'relu'}},\n",
    "                    29:{'layer':tf.keras.layers.Dense,\n",
    "                        'params':{'units':40,'activation':'relu'}}, \n",
    "                    30:{'layer':tf.keras.layers.Dense,\n",
    "                        'params':{'units':20,'activation':'relu'}},\n",
    "                    31:{'layer':tf.keras.layers.Dense,\n",
    "                        'params':{'units':10,'activation':'relu'}},\n",
    "                    32:{'layer':tf.keras.layers.Dense,\n",
    "                        'params':{'units':5,'activation':'relu'}},\n",
    "                    33:{'layer':None,\n",
    "                        'params':{}},\n",
    "                    34:{'layer':tf.keras.layers.Dropout,\n",
    "                        'params':{'rate':0.5}},\n",
    "                    35:{'layer':tf.keras.layers.Dropout,\n",
    "                        'params':{'rate':0.25}},\n",
    "                    36:{'layer':tf.keras.layers.Dropout,\n",
    "                        'params':{'rate':0.15}}\n",
    "                        \n",
    "                    }\n",
    "\n",
    "    pool_of_features_probability=np.array([3,3,3,3,3,3,3,3,3,3,3,3,3,3,20,3,3,3,3,3,3,3,3,9,3,3,3,3,3,3,3,3,20,2,2,2])\n",
    "    pool_of_features_probability=pool_of_features_probability/pool_of_features_probability.sum()\n",
    "    return pool_of_features,pool_of_features_probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA NAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_flatten_need(model:tf.keras.Sequential,layer_to_be_add:tf.keras.layers,debug=False)->tf.keras.Sequential:\n",
    "    \n",
    "    \"\"\"\n",
    "        Checks if it is required to add a flatten layern, in order of connect dense layers into Convolutional and Maxpooling layers.\n",
    "    \"\"\"\n",
    "    assert 'dense' not in tf.keras.layers.BatchNormalization.__doc__.lower()[:30]\n",
    "    assert 'dense' not in tf.keras.layers.Conv2D.__doc__.lower()[:30]\n",
    "    assert 'dense' not in tf.keras.layers.MaxPooling2D.__doc__.lower()[:30]\n",
    "    assert 'dense' not in tf.keras.layers.GlobalAvgPool2D.__doc__.lower()[:30]\n",
    "    assert 'dense' in tf.keras.layers.Dense.__doc__.lower()[:30]\n",
    "\n",
    "    assert 'conv' not in tf.keras.layers.BatchNormalization.__doc__.lower()[:30]\n",
    "    assert 'conv' in tf.keras.layers.Conv2D.__doc__.lower()[:30]\n",
    "    assert 'conv' not in tf.keras.layers.MaxPooling2D.__doc__.lower()[:30]\n",
    "    assert 'conv' not in tf.keras.layers.GlobalAvgPool2D.__doc__.lower()[:30]\n",
    "    assert 'conv' not in tf.keras.layers.Dense.__doc__.lower()[:30]\n",
    "\n",
    "    assert 'pool' not in tf.keras.layers.BatchNormalization.__doc__.lower()[:30]\n",
    "    assert 'pool' not in tf.keras.layers.Conv2D.__doc__.lower()[:30]\n",
    "    assert 'pool' in tf.keras.layers.MaxPooling2D.__doc__.lower()[:30]\n",
    "    assert 'pool' in tf.keras.layers.GlobalAvgPool2D.__doc__.lower()[:30]\n",
    "    assert 'pool' not in tf.keras.layers.Dense.__doc__.lower()[:30]\n",
    "    \n",
    "    if debug:\n",
    "        print('layer to add :',layer_to_be_add)\n",
    "    layers=model.layers\n",
    "    if len(layers)>1:\n",
    "        if 'dense' in layer_to_be_add.__doc__.lower()[:30]:\n",
    "            for previus_layer in np.flip(layers):\n",
    "                if 'dense' in previus_layer.__doc__.lower()[:30] or 'flat' in previus_layer.__doc__.lower()[:30] :\n",
    "                    break\n",
    "                elif ('conv' in previus_layer.__doc__.lower()[:30] or 'pool' in previus_layer.__doc__.lower()[:30]):\n",
    "                    model.add(tf.keras.layers.Flatten())\n",
    "                    break\n",
    "    return model\n",
    "\n",
    "def architecture_feaseable(individual,debug=False):\n",
    "    \"\"\"\n",
    "    creates the model indicated by the individual. \n",
    "    \"\"\"\n",
    "    model=tf.keras.Sequential()\n",
    "    non_empty_layer=0\n",
    "    for (index,gene) in enumerate(individual):\n",
    "        layer_details=pool_of_features[gene]      \n",
    "        \n",
    "              \n",
    "        if layer_details['layer'] is not None:\n",
    "            \n",
    "            if non_empty_layer==0:\n",
    "                layer_details['params']['input_shape']=(100,100,3)\n",
    "                layer=layer_details['layer'](**layer_details['params'])\n",
    "            else:\n",
    "                model=check_flatten_need(model,layer,debug=debug)\n",
    "                layer=layer_details['layer'](**layer_details['params'])\n",
    "            \n",
    "            try:            \n",
    "                model.add(layer)\n",
    "            except ValueError:\n",
    "                model=None\n",
    "                break\n",
    "\n",
    "    if model is None:\n",
    "        return [-1]*len(individual)\n",
    "    else:\n",
    "        return individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_flatten_need(model:tf.keras.Sequential,layer_to_be_add:tf.keras.layers,debug=False)->tf.keras.Sequential:\n",
    "    \n",
    "    \"\"\"\n",
    "        Checks if it is required to add a flatten layern, in order of connect dense layers into Convolutional and Maxpooling layers.\n",
    "    \"\"\"\n",
    "    assert 'dense' not in tf.keras.layers.BatchNormalization.__doc__.lower()[:30]\n",
    "    assert 'dense' not in tf.keras.layers.Conv2D.__doc__.lower()[:30]\n",
    "    assert 'dense' not in tf.keras.layers.MaxPooling2D.__doc__.lower()[:30]\n",
    "    assert 'dense' not in tf.keras.layers.GlobalAvgPool2D.__doc__.lower()[:30]\n",
    "    assert 'dense' in tf.keras.layers.Dense.__doc__.lower()[:30]\n",
    "\n",
    "    assert 'conv' not in tf.keras.layers.BatchNormalization.__doc__.lower()[:30]\n",
    "    assert 'conv' in tf.keras.layers.Conv2D.__doc__.lower()[:30]\n",
    "    assert 'conv' not in tf.keras.layers.MaxPooling2D.__doc__.lower()[:30]\n",
    "    assert 'conv' not in tf.keras.layers.GlobalAvgPool2D.__doc__.lower()[:30]\n",
    "    assert 'conv' not in tf.keras.layers.Dense.__doc__.lower()[:30]\n",
    "\n",
    "    assert 'pool' not in tf.keras.layers.BatchNormalization.__doc__.lower()[:30]\n",
    "    assert 'pool' not in tf.keras.layers.Conv2D.__doc__.lower()[:30]\n",
    "    assert 'pool' in tf.keras.layers.MaxPooling2D.__doc__.lower()[:30]\n",
    "    assert 'pool' in tf.keras.layers.GlobalAvgPool2D.__doc__.lower()[:30]\n",
    "    assert 'pool' not in tf.keras.layers.Dense.__doc__.lower()[:30]\n",
    "    \n",
    "    if debug:\n",
    "        print('layer to add :',layer_to_be_add)\n",
    "    layers=model.layers\n",
    "    if len(layers)>1:\n",
    "        if 'dense' in layer_to_be_add.__doc__.lower()[:30]:\n",
    "            for previus_layer in np.flip(layers):\n",
    "                if 'dense' in previus_layer.__doc__.lower()[:30] or 'flat' in previus_layer.__doc__.lower()[:30] :\n",
    "                    break\n",
    "                elif ('conv' in previus_layer.__doc__.lower()[:30] or 'pool' in previus_layer.__doc__.lower()[:30]):\n",
    "                    model.add(tf.keras.layers.Flatten())\n",
    "                    break\n",
    "    return model\n",
    "\n",
    "def architecture_feaseable(pool_of_features,individual,debug=False):\n",
    "    \"\"\"\n",
    "    creates the model indicated by the individual. \n",
    "    \"\"\"\n",
    "    model=tf.keras.Sequential()\n",
    "    non_empty_layer=0\n",
    "    for (index,gene) in enumerate(individual):\n",
    "        layer_details=pool_of_features[gene]      \n",
    "        \n",
    "            \n",
    "        if layer_details['layer'] is not None:\n",
    "            \n",
    "            if non_empty_layer==0:\n",
    "                layer_details['params']['input_shape']=(100,100,3)\n",
    "                layer=layer_details['layer'](**layer_details['params'])\n",
    "            else:\n",
    "                model=check_flatten_need(model,layer,debug=debug)\n",
    "                layer=layer_details['layer'](**layer_details['params'])\n",
    "            \n",
    "            try:            \n",
    "                model.add(layer)\n",
    "            except ValueError:\n",
    "                model=None\n",
    "                break\n",
    "\n",
    "    if model is None:\n",
    "        return [-1]*len(individual)\n",
    "    else:\n",
    "        return individual\n",
    "\n",
    "\n",
    "def generate_individuals(pool_of_features,pool_of_features_probability,max_depth):\n",
    "        pool_individuals=np.random.choice(list(pool_of_features.keys()),size=(1000,max_depth),p=pool_of_features_probability)\n",
    "        pool_individuals_valids=[]\n",
    "        for ind in pool_individuals:   \n",
    "            pool_individuals_valids.append(architecture_feaseable(pool_of_features=pool_of_features,individual=ind))\n",
    "\n",
    "        pool_individuals_valids=np.array(pool_individuals_valids)\n",
    "        pool_individuals_valids=pool_individuals_valids[np.where(pool_individuals_valids.sum(axis=1)>0)[0]]\n",
    "\n",
    "        with open(f'arquiteturas_validas_max_depth_{max_depth}.json','+w') as f:\n",
    "            json.dump(pool_individuals_valids.tolist(),f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function and Enconding (f:individual -> Neural Network )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_random_layer()->tf.keras.layers:\n",
    "    \"\"\" selects one random layer from the pool of features\"\"\"\n",
    "    layer_index=np.random.choice(list(pool_of_features.keys()),1,p=pool_of_features_probability)[0]\n",
    "    layer_details=pool_of_features[layer_index]\n",
    "    if layer_details['layer'] is not None:\n",
    "        layer=layer_details['layer'](**layer_details['params'])\n",
    "    else:\n",
    "        layer=get_random_layer()\n",
    "        \n",
    "    \n",
    "    return layer\n",
    "\n",
    "def check_dimension_compatibility(model:tf.keras.Sequential,layer:tf.keras.layers,debug=False) -> tf.keras.layers:\n",
    "    \"\"\"\n",
    "    checks if it is feasible to add the intended layer \n",
    "    \"\"\"\n",
    "    try:\n",
    "        ### dumb way of check compatibilty\n",
    "        model.add(layer)\n",
    "        model.pop()\n",
    "        \n",
    "    except ValueError:\n",
    "        if debug:\n",
    "            print('Dimension compatibility error')\n",
    "\n",
    "        layer=get_random_layer()\n",
    "        layer=check_dimension_compatibility(model,layer)\n",
    "\n",
    "    if debug:\n",
    "        print('dimension outcome:',layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def check_flatten_need(model:tf.keras.Sequential,layer_to_be_add:tf.keras.layers,debug=False)->tf.keras.Sequential:\n",
    "    \n",
    "    \"\"\"\n",
    "        Checks if it is required to add a flatten layern, in order of connect dense layers into Convolutional and Maxpooling layers.\n",
    "    \"\"\"\n",
    "    assert 'dense' not in tf.keras.layers.BatchNormalization.__doc__.lower()[:30]\n",
    "    assert 'dense' not in tf.keras.layers.Conv2D.__doc__.lower()[:30]\n",
    "    assert 'dense' not in tf.keras.layers.MaxPooling2D.__doc__.lower()[:30]\n",
    "    assert 'dense' not in tf.keras.layers.GlobalAvgPool2D.__doc__.lower()[:30]\n",
    "    assert 'dense' in tf.keras.layers.Dense.__doc__.lower()[:30]\n",
    "\n",
    "    assert 'conv' not in tf.keras.layers.BatchNormalization.__doc__.lower()[:30]\n",
    "    assert 'conv' in tf.keras.layers.Conv2D.__doc__.lower()[:30]\n",
    "    assert 'conv' not in tf.keras.layers.MaxPooling2D.__doc__.lower()[:30]\n",
    "    assert 'conv' not in tf.keras.layers.GlobalAvgPool2D.__doc__.lower()[:30]\n",
    "    assert 'conv' not in tf.keras.layers.Dense.__doc__.lower()[:30]\n",
    "\n",
    "    assert 'pool' not in tf.keras.layers.BatchNormalization.__doc__.lower()[:30]\n",
    "    assert 'pool' not in tf.keras.layers.Conv2D.__doc__.lower()[:30]\n",
    "    assert 'pool' in tf.keras.layers.MaxPooling2D.__doc__.lower()[:30]\n",
    "    assert 'pool' in tf.keras.layers.GlobalAvgPool2D.__doc__.lower()[:30]\n",
    "    assert 'pool' not in tf.keras.layers.Dense.__doc__.lower()[:30]\n",
    "    \n",
    "    if debug:\n",
    "        print('layer to add :',layer_to_be_add)\n",
    "    layers=model.layers\n",
    "    if len(layers)>0:\n",
    "        if 'dense' in layer_to_be_add.__doc__.lower()[:30]:\n",
    "            for previus_layer in np.flip(layers):\n",
    "                if 'dense' in previus_layer.__doc__.lower()[:30] or 'flat' in previus_layer.__doc__.lower()[:30] :\n",
    "                    break\n",
    "                elif ('conv' in previus_layer.__doc__.lower()[:30] or 'pool' in previus_layer.__doc__.lower()[:30]):\n",
    "                    model.add(tf.keras.layers.Flatten())\n",
    "                    break\n",
    "    return model\n",
    "\n",
    "def create_model(pool_of_features,individual,debug=False):\n",
    "    \"\"\"\n",
    "    creates the model indicated by the individual. \n",
    "    \"\"\"\n",
    "    model=tf.keras.Sequential()\n",
    "    non_empty_layer=0\n",
    "    for (index,gene) in enumerate(individual):\n",
    "        layer_details=pool_of_features[gene]      \n",
    "                    \n",
    "        if layer_details['layer'] != None:\n",
    "            \n",
    "            if non_empty_layer==0:\n",
    "                layer_details['params']['input_shape']=(100,100,3)\n",
    "                layer=layer_details['layer'](**layer_details['params'])\n",
    "            else:\n",
    "                layer=layer_details['layer'](**layer_details['params'])\n",
    "                model=check_flatten_need(model,layer,debug=debug)\n",
    "                layer=layer_details['layer'](**layer_details['params'])\n",
    "                layer=check_dimension_compatibility(model,layer,debug=debug)\n",
    "            \n",
    "            model.add(layer)\n",
    "            non_empty_layer+=1   \n",
    "\n",
    "            \n",
    "    layer=tf.keras.layers.Dense(2,activation='softmax')\n",
    "    model=check_flatten_need(model,layer)\n",
    "    model.add(layer)\n",
    "    if debug:\n",
    "            print('model stack:',*model.layers,sep='\\n')\n",
    "\n",
    "    learning_rate=tf.optimizers.schedules.ExponentialDecay(initial_learning_rate=.1,decay_steps=10000.,decay_rate=0.95)\n",
    "    opt=tf.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss=tf.metrics.mse,metrics=tf.metrics.AUC(name='auc'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(trainning_dataset,validation_dataset,model:tf.keras.Sequential,individual,seed=None,verbose=0,max_epochs=20,display=False)-> tf.keras.Sequential:\n",
    "\n",
    "    if str(seed)+str(individual) not in space_checked.keys():\n",
    "        log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_auc', patience=3)\n",
    "        model.fit(trainning_dataset,validation_data=validation_dataset,epochs=max_epochs,verbose=verbose,callbacks=[callback,tensorboard_callback])   \n",
    "        space_checked[str(seed)+str(individual)]=model\n",
    "    else:\n",
    "        model=space_checked[str(seed)+str(individual) ]\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(testing_dataset,model:tf.keras.Sequential,verbose=0)->float:\n",
    "    _,metric=model.evaluate(testing_dataset,verbose=verbose)\n",
    "    return metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing=False\n",
    "if testing:\n",
    "    individual=[12,#conv\n",
    "                16,#pooling\n",
    "                15,#norm\n",
    "                33,#empty\n",
    "                34,#dropout\n",
    "                1,#conv\n",
    "                2,#conv\n",
    "                3,#conv\n",
    "                33#empty\n",
    "                ]\n",
    "    model=create_model(individual,debug=True)\n",
    "    model=train_model(model,individual,verbose=1)\n",
    "    evaluate_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing:\n",
    "    for individual in np.random.choice(list(pool_of_features.keys()),size=(100,max_depths),p=pool_of_features_probability):\n",
    "        \n",
    "        model=create_model(individual)\n",
    "        print(individual,model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def choice(a,p):\n",
    "    return np.random.choice(a=a,size=1,p=p)[0]\n",
    "\n",
    "def initIndividual(icls, content):\n",
    "    return icls(content)\n",
    "\n",
    "def initPopulation(pcls, ind_init,pop_size,trial_name:str, filename:str):\n",
    "    with open(filename, \"r\") as pop_file:\n",
    "        contents = np.array(json.load(pop_file))\n",
    "    # contents=np.array(contents)\n",
    "    index_ind_selected=np.random.choice(np.arange(0,len(contents)),size=pop_size,replace=False)\n",
    "    pop=contents[index_ind_selected,:]\n",
    "\n",
    "    with open(trial_name+'_population_selected.json','w') as f:\n",
    "        json.dump(pop.tolist(),f)\n",
    "\n",
    "    return pcls(ind_init(c) for c in pop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id=''\n",
    "max_depth=15\n",
    "population_size=2\n",
    "generations=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 17:35:13.320647: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-11-25 17:35:13.320696: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: estevanmendes-Inspiron-15-3511\n",
      "2023-11-25 17:35:13.320706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: estevanmendes-Inspiron-15-3511\n",
      "2023-11-25 17:35:13.320831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 470.223.2\n",
      "2023-11-25 17:35:13.320857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 470.223.2\n",
      "2023-11-25 17:35:13.320862: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 470.223.2\n"
     ]
    }
   ],
   "source": [
    "def evaluate(individual,trainning_dataset,validation_dataset,testing_dataset,pool_of_features,fn_no_linear=None,max_epochs=20,num_of_evaluations=1,verbose=0,display=False):\n",
    "    if display:\n",
    "        print('model {} is being trainned')\n",
    "\n",
    "    seeds=[1234,345,121,132,234]\n",
    "    metrics=[]\n",
    "    for seed in seeds[:num_of_evaluations]:\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        tf.random.set_seed(seed)\n",
    "        model=create_model(pool_of_features,individual)\n",
    "        if seed==seeds[0]:\n",
    "            print('\\n'*2)\n",
    "            print(f'individual: {individual}')\n",
    "            print(model.summary())\n",
    "            print('\\n'*2)\n",
    "\n",
    "        model=train_model(trainning_dataset,\n",
    "                          validation_dataset,\n",
    "                          model,\n",
    "                          individual,\n",
    "                          seed=seed,\n",
    "                          max_epochs=max_epochs,\n",
    "                          verbose=verbose)\n",
    "        metrics.append(evaluate_model(testing_dataset,model,verbose=verbose))\n",
    "    metrics=np.mean(metrics)\n",
    "    if fn_no_linear!=None:\n",
    "        metrics=fn_no_linear(metrics)\n",
    "\n",
    "    \n",
    "    return metrics,\n",
    "\n",
    "\n",
    "global pool_of_features\n",
    "global pool_of_features_probability\n",
    "trainning_dataset,validation_dataset,testing_dataset=load_datasets()\n",
    "pool_of_features,pool_of_features_probability=individuals(max_depth=max_depth)\n",
    "\n",
    "\n",
    "if not os.path.isfile(f'arquiteturas_validas_max_depth_{max_depth}.json'): \n",
    "    print('Pool of valid archtectures about to be created')\n",
    "    generate_individuals(pool_of_features,pool_of_features_probability,max_depth=max_depth)\n",
    "    \n",
    "global space_checked\n",
    "space_checked={}\n",
    "\n",
    "\n",
    "\n",
    "history = tools.History()\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "toolbox = base.Toolbox()\n",
    "# toolbox.register(\"attribute\", choice,a=list(pool_of_features.keys()),p=pool_of_features_probability)\n",
    "# toolbox.register(\"individual\", tools.initRepeat, creator.Individual,toolbox.attribute, n=15)\n",
    "# toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"individual_guess\", initIndividual, creator.Individual)\n",
    "toolbox.register(\"population_guess\", initPopulation, list, toolbox.individual_guess, filename=f\"arquiteturas_validas_max_depth_{max_depth}.json\",trial_name=id)\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt,low=0,up=len(pool_of_features), indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evaluate,trainning_dataset=trainning_dataset.batch(10),\n",
    "                                    validation_dataset=validation_dataset.batch(10),\n",
    "                                    testing_dataset=testing_dataset.batch(32),\n",
    "                                    pool_of_features=pool_of_features,\n",
    "                                    num_of_evaluations=1,\n",
    "                                    fn_no_linear=lambda x: x**3,\n",
    "                                    max_epochs=1,\n",
    "                                    verbose=1)\n",
    "\n",
    "# Decorate the variation operators\n",
    "toolbox.decorate(\"mate\", history.decorator)\n",
    "toolbox.decorate(\"mutate\", history.decorator)\n",
    "\n",
    "population = toolbox.population_guess(pop_size=population_size)\n",
    "history.update(population)\n",
    "\n",
    "\n",
    "hof = tools.HallOfFame(1)  # salva o melhor individuo que já existiu na pop durante a evolução\n",
    "\n",
    "# Gerar as estatísticas\n",
    "stats = tools.Statistics(lambda ind:ind.fitness.values)\n",
    "stats.register('avg', np.mean)\n",
    "stats.register('std', np.std)\n",
    "stats.register('min', np.min)\n",
    "stats.register('max', np.max)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "individual: [33, 5, 9, 3, 15, 10, 1, 7, 6, 28, 12, 33, 15, 33, 12]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 98, 98, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 96, 96, 8)         4616      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 92, 92, 16)        3216      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 92, 92, 16)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 92, 92, 64)        1088      \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 88, 88, 64)        102464    \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 86, 86, 16)        9232      \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 84, 84, 32)        4640      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 225792)            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                13547580  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                610       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 10)                40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13675474 (52.17 MB)\n",
      "Trainable params: 13675422 (52.17 MB)\n",
      "Non-trainable params: 52 (208.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "173/173 [==============================] - 47s 265ms/step - loss: 0.2213 - auc: 0.6844 - val_loss: 0.3079 - val_auc: 0.5404\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 0.3081 - auc: 0.5487\n",
      "\n",
      "\n",
      "\n",
      "individual: [33, 34, 15, 15, 18, 8, 4, 12, 31, 33, 10, 36, 33, 15, 15]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout (Dropout)           (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 100, 100, 3)       12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 100, 100, 3)       12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 3)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 14, 14, 8)         224       \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 10, 10, 8)         1608      \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 10, 10, 16)        144       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 10)                40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 10)                40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18222 (71.18 KB)\n",
      "Trainable params: 18170 (70.98 KB)\n",
      "Non-trainable params: 52 (208.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "173/173 [==============================] - 6s 31ms/step - loss: 0.2626 - auc: 0.4822 - val_loss: 0.2548 - val_auc: 0.5342\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.2552 - auc: 0.5130\n",
      "gen\tnevals\tavg     \tstd      \tmin     \tmax     \n",
      "0  \t2     \t0.150139\t0.0151019\t0.135037\t0.165241\n",
      "\n",
      "\n",
      "\n",
      "individual: [33, 5, 9, 3, 15, 10, 1, 7, 6, 28, 12, 33, 15, 33, 12]\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_27 (Conv2D)          (None, 98, 98, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 96, 96, 8)         4616      \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 92, 92, 16)        3216      \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 92, 92, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 92, 92, 64)        1088      \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 88, 88, 64)        102464    \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 86, 86, 16)        9232      \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 84, 84, 32)        4640      \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 225792)            0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 60)                13547580  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                610       \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 10)                40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13675474 (52.17 MB)\n",
      "Trainable params: 13675422 (52.17 MB)\n",
      "Non-trainable params: 52 (208.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "12/12 [==============================] - 3s 224ms/step - loss: 0.3081 - auc: 0.5487\n",
      "\n",
      "\n",
      "\n",
      "individual: [33, 5, 9, 3, 15, 10, 1, 7, 6, 28, 12, 33, 15, 33, 12]\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_45 (Conv2D)          (None, 98, 98, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 96, 96, 8)         4616      \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 92, 92, 16)        3216      \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 92, 92, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 92, 92, 64)        1088      \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 88, 88, 64)        102464    \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 86, 86, 16)        9232      \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 84, 84, 32)        4640      \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 225792)            0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 60)                13547580  \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                610       \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 10)                40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13675474 (52.17 MB)\n",
      "Trainable params: 13675422 (52.17 MB)\n",
      "Non-trainable params: 52 (208.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "12/12 [==============================] - 3s 223ms/step - loss: 0.3081 - auc: 0.5487\n",
      "1  \t2     \t0.165241\t0        \t0.165241\t0.165241\n",
      "2  \t0     \t0.165241\t0        \t0.165241\t0.165241\n",
      "melhor: [33, 5, 9, 3, 15, 10, 1, 7, 6, 28, 12, 33, 15, 33, 12]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_63 (Conv2D)          (None, 98, 98, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 96, 96, 8)         4616      \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 92, 92, 16)        3216      \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 92, 92, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 92, 92, 64)        1088      \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 88, 88, 64)        102464    \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 86, 86, 16)        9232      \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 84, 84, 32)        4640      \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 225792)            0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 60)                13547580  \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 5)                 305       \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 5)                 20        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 5)                 20        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13675049 (52.17 MB)\n",
      "Trainable params: 13674997 (52.17 MB)\n",
      "Non-trainable params: 52 (208.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "individual: [33, 5, 9, 3, 15, 10, 1, 7, 6, 28, 12, 33, 15, 33, 12]\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_82 (Conv2D)          (None, 98, 98, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          (None, 96, 96, 8)         4616      \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          (None, 92, 92, 16)        3216      \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 92, 92, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_88 (Conv2D)          (None, 92, 92, 64)        1088      \n",
      "                                                                 \n",
      " conv2d_90 (Conv2D)          (None, 88, 88, 64)        102464    \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 86, 86, 16)        9232      \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          (None, 84, 84, 32)        4640      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 225792)            0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 60)                13547580  \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                610       \n",
      "                                                                 \n",
      " batch_normalization_28 (Ba  (None, 10)                40        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13675474 (52.17 MB)\n",
      "Trainable params: 13675422 (52.17 MB)\n",
      "Non-trainable params: 52 (208.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "(0.5487474203109741,)\n"
     ]
    }
   ],
   "source": [
    "pop, log = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.01, ngen=generations, stats=stats, halloffame=hof, verbose=True)\n",
    "\n",
    "print('melhor:',hof[0])\n",
    "print(create_model(pool_of_features,hof[0],).summary())\n",
    "print(evaluate(hof[0],trainning_dataset=trainning_dataset.batch(10),\n",
    "                                    validation_dataset=validation_dataset.batch(10),\n",
    "                                    testing_dataset=testing_dataset.batch(32),\n",
    "                                    pool_of_features=pool_of_features,\n",
    "                                    num_of_evaluations=1,\n",
    "                                    ))\n",
    "\n",
    "with open(f'id_{id}_individuals_generation.txt','w') as f:\n",
    "    for ind in hof:\n",
    "        f.write(str(ind)+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [33, 5, 9, 3, 15, 10, 1, 7, 6, 28, 12, 33, 15, 33, 12],\n",
       " 2: [33, 34, 15, 15, 18, 8, 4, 12, 31, 33, 10, 36, 33, 15, 15],\n",
       " 3: [33, 5, 9, 3, 15, 10, 1, 7, 6, 28, 12, 33, 15, 33, 12],\n",
       " 4: [33, 5, 9, 3, 15, 10, 1, 7, 6, 28, 12, 33, 15, 33, 12]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.genealogy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 5, 9, 3, 15, 10, 1, 7, 6, 28, 12, 33, 15, 33, 12]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hof[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_model() missing 1 required positional argument: 'individual'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/estevanmendes/Desktop/PUC_RIO/deep_LEARNING/dados/NAS_GA.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/estevanmendes/Desktop/PUC_RIO/deep_LEARNING/dados/NAS_GA.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m create_model(hof[\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39msummary()\n",
      "\u001b[0;31mTypeError\u001b[0m: create_model() missing 1 required positional argument: 'individual'"
     ]
    }
   ],
   "source": [
    "create_model(hof[0]).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(hof[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f'experiment_gen_{generations}_pop_{population_size}_{datetime.datetime.now()}.json','w+') as f:\n",
    "  json.dump(log,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
